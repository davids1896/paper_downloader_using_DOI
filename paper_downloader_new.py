import os
import requests
from bs4 import BeautifulSoup
import time

# Sci-Hub ç½‘å€ï¼ˆå¯èƒ½éœ€è¦æ›´æ–°ï¼‰
SCI_HUB_URL = "https://sci-hub.st/"

# è¯»å–DOIåˆ—è¡¨
def read_doi_list(file_path):
    with open(file_path, "r", encoding="utf-8") as f:
        dois = [line.strip() for line in f if line.strip()]
    return dois

# è·å–Sci-Hubä¸Šçš„PDFé“¾æ¥
def get_pdf_url(doi):
    url = f"{SCI_HUB_URL}{doi}"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/132.0.0.0 Safari/537.36"
    }
    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, "html.parser")
        iframe = soup.find("iframe")
        if iframe and "src" in iframe.attrs:
            pdf_url = iframe["src"]
            if pdf_url.startswith("//"):
                pdf_url = "https:" + pdf_url
            return pdf_url
    except requests.RequestException as e:
        print(f"âŒ DOI {doi} è®¿é—®å¤±è´¥: {e}")
    
    return None

# ä¸‹è½½PDF
def download_pdf(pdf_url, doi, save_dir="downloads"):
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)

    filename = os.path.join(save_dir, f"{doi.replace('/', '_')}.pdf")
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/132.0.0.0 Safari/537.36"
    }

    try:
        with requests.get(pdf_url, headers=headers, stream=True, timeout=15) as r:
            r.raise_for_status()
            with open(filename, "wb") as f:
                for chunk in r.iter_content(chunk_size=8192):
                    f.write(chunk)
        print(f"âœ… æˆåŠŸä¸‹è½½: {filename}")
    except requests.RequestException as e:
        print(f"âŒ ä¸‹è½½ {doi} å¤±è´¥: {e}")

# æ‰¹é‡ä¸‹è½½æ–‡çŒ®
def batch_download(file_path):
    dois = read_doi_list(file_path)
    
    for doi in dois:
        print(f"ğŸ” å¤„ç† DOI: {doi}")
        pdf_url = get_pdf_url(doi)
        print(f"ğŸ”— PDFé“¾æ¥: {pdf_url}")

        if pdf_url:
            download_pdf(pdf_url, doi)
        else:
            print(f"âš ï¸ æ— æ³•è·å– {doi} çš„PDFé“¾æ¥")
        
        time.sleep(3)  # é¿å…è¯·æ±‚è¿‡å¿«è¢«å°

if __name__ == "__main__":
    batch_download("test.txt")
